# **Integrated RAG System â€“ Local LLMs with Up-to-Date Knowledge**

This project is designed to **bridge the gap between locally run LLMs and real-time web knowledge**. Unlike traditional AI models that rely on outdated static datasets, this **Retrieval-Augmented Generation (RAG) system** dynamically searches the web, extracts relevant information, and enhances LLM responses with fresh, up-to-date contextâ€”all while running entirely **on your local machine**.

## **Why This Matters**
Most LLMs are limited to the knowledge they were trained on. This system **eliminates that constraint** by:
âœ… **Fetching the latest data from the web** instead of relying on old training sets.  
âœ… **Running fully locally**â€”no need for cloud-based APIs or external dependencies.  
âœ… **Combining powerful search & retrieval** with AI-driven answers.  

## **How It Works**
1ï¸âƒ£ **Finds the Best Sources** â€“ Uses **Google Custom Search API** to locate relevant articles.  
2ï¸âƒ£ **Extracts Clean Data** â€“ Scrapes text from web pages & PDFs, removing ads and clutter.  
3ï¸âƒ£ **Processes & Organizes Content** â€“ Chunks and embeds text for fast retrieval.  
4ï¸âƒ£ **Stores Knowledge Locally** â€“ Saves extracted data in **ChromaDB**, a local vector database.  
5ï¸âƒ£ **Enhances Your Local LLM** â€“ Uses **retrieved context** to generate accurate, up-to-date answers.  

## **Key Features**
ğŸš€ **Run LLMs with current data** â€“ Keep your AI informed without retraining.  
ğŸ” **Web-enhanced question answering** â€“ Get **real-time, reliable answers** from local models.  
ğŸ“‚ **Works with documents** â€“ Scrapes and processes PDFs & webpages.  
ğŸ’¾ **Fully Local & Privacy-Friendly** â€“ Your data stays on your machine.  
ğŸ’¡ **Optimized for lightweight models** â€“ Works with **TinyLlama-1.1B-Chat**, but adaptable to others.  

## **Installation**
### **Prerequisites**
Ensure you have the following installed:
- Python 3.8+
- Google Custom Search API Key (for web search)
- Required Python libraries

### **Setup**
1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/integrated-rag-system.git
   cd integrated-rag-system
   ```
2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
3. **Set up environment variables:**
   ```bash
   export GOOGLE_API_KEY="your_google_api_key"
   export GOOGLE_CSE_ID="your_custom_search_engine_id"
   ```

## **Usage**
To **search the web and get an AI-generated answer**:
```bash
python main.py --query "What is thrombosis?"
```

To **query locally stored knowledge without searching the web**:
```bash
python main.py --query "What is thrombosis?" --skip-search
```

## **Under the Hood**
- **Google Search API** â€“ Finds relevant web sources  
- **Playwright & BeautifulSoup** â€“ Extracts clean text from web pages  
- **PyPDF2** â€“ Parses PDFs for additional knowledge  
- **ChromaDB** â€“ Stores and retrieves contextual information locally  
- **SentenceTransformers** â€“ Finds the most relevant data using embeddings  
- **TinyLlama-1.1B-Chat** â€“ Provides AI-generated answers with context-aware retrieval  

## **Who Is This For?**
âœ”ï¸ Developers who want to **enhance their LLMs with real-time data**  
âœ”ï¸ Researchers who need **accurate, up-to-date insights**  
âœ”ï¸ Privacy-conscious users who prefer **local AI processing**  


### **Contribute**
1. **Fork the repository**
2. **Create a feature branch**
3. **Submit a pull request**

---
â­ **If you find this project useful, don't forget to give it a star!** â­
